# Inside cover

### A Field Guide to "Fake News" and Other Information Disorders 

Compiled by **Liliana Bounegru, Jonathan Gray, Tommaso Venturini** and **Michele Mauri**

This guide explores the use of digital methods to study false viral news, political memes, trolling practices and their social life online. It is a project of the **Public Data Lab** with support from **First Draft**.

The Public Data Lab ([publicdatalab.org](www.publicdatalab.org)) is an interdisciplinary network seeking to facilitate research, democratic engagement and public debate around the future of the data society.

First Draft ([firstdraftnews.com](www.firstdraftnews.com)) is dedicated to improving skills and standards in the reporting and sharing of information that emerges online. 

© 2017 Public Data Lab. Amsterdam

The guide is released under the Creative Commons Attribution License ([creativecommons.org/licenses/by/4.0/](https://creativecommons.org/licenses/by/4.0/)). We strongly encourage you to freely share, adapt and draw on this work – with only the condition that you give credit, as per the terms of the license. 

If you reproduce or draw on material from this guide, we’d be grateful if you could credit and link back as per the following statement:

“This article draws on *A Field Guide to "Fake News" and Other Information Disorders*, a collaboration of the Public Data Lab and First Draft. For further details see: http://fakenews.publicdatalab.org”

The copyright for the research that this guide draws upon remains with its respective contributors.


This project would not have been possible without the contributions of researchers from the following institutions:

* **Centre for Journalism Studies,** University of Ghent (NL)
* **Citizen Data Lab,** Amsterdam University of Applied Sciences (NL)
* **DensityDesign Lab,** Politecnico di Milano (IT)
* **Digital Methods Initiative,** Media Studies, University of Amsterdam (NL)
* **Govcom.org Foundation,** Amsterdam
* **Institut National de Recherche en Informatique et en Automatique (INRIA)** (FR)
* **Institute for Policy Research,** University of Bath (UK)
* **King’s College London** (UK)
* **Laboratoire d’Étude des Sciences et des Techniques (STS-Lab),** Université de Lausanne (CH)
* **Laboratoire Interdisciplinaire Sciences Innovations Sociétés (LISIS),** Université Paris-Est Marne-la-Vallée (FR)
* **Médialab,** Sciences Po, Paris (FR)
* **Techno-Anthropology Lab,** Aalborg University Copenhagen (DK)
* **University of Siegen** (DE)

Published by Public Data Lab.

Released in December 2017.

# Contents

7	Introduction


15	Conventions used in the book


CHAPTER 1
17	MAPPING FAKE NEWS HOTSPOTS ON FACEBOOK
20	1. What publics does fake news animate on Facebook?
40	2. How may the trajectory of a fake news story be traced on Facebook?
52	3. Do fact-checking initiatives reach the publics of fake news on Facebook?


CHAPTER 2
61	TRACING THE CIRCULATION OF FAKE NEWS ON THE WEB
64	1. Where do fake news originate? By what sites are they first retransmitted?
78	2. Which are the most visible sources related to a fake story? When and by whom are they mentioned?


CHAPTER 3
95	USING TRACKER SIGNATURES TO MAP THE TECHNO-COMMERCIAL UNDERPINNINGS OF FAKE NEWS SITES
97	1. Do fake news sites use different kinds of trackers from mainstream media sites?
103	2. How can fake news and mainstream media sites be profiled based on their tracker usage?
109	3. How do tracker ecologies on fake news sites change over time?
115	4. Which other websites share the same tracker IDs as fake news sites?
121	5. Do trackers associated with hyper-partisan and misleading information sites vary across language spheres?


CHAPTER 4
127 STUDYING POLITICAL MEMES ON FACEBOOK
130	1. How can meme spaces on Facebook be traced?
139	2. How do memes frame political and media events?
148	3. How may the content of memes be studied?


CHAPTER 5
161	MAPPING TROLL-LIKE PRACTICES - ON TWITTER
165	1. How may we detect Twitter accounts which negatively target political representatives?
172	2. How may we characterise the sources of troll-like activity?
184	3. How may troll-like practices be characterised?


199	Conclusion


203	Glossaries

210	Contributors and acknowledgements

# Introduction

What is “fake news”? And what can be done about it? Depending on who you ask, fake news is said to represent a step-change in information warfare; an emerging form of cynical profiteering; an engine for energising “alt-right” and other digitally mediated grassroots political mobilisations around the world; a partisan battle cry for a new liberal “ministry of truth”; an unwanted byproduct of the online platforms which organise our digital societies; or a canary call signalling a collapse of consensus around established institutions and processes of knowledge production, heralding a new “post-truth” era in politics and public life.

According to some commentators fake news is just old wine in new bottles – and similar misleading information phenomena have existed for at least as long as the printing press and other communication technologies through which they circulate.[1] Others suggest that new online platforms accelerate and “supercharge” their circulation in a way which introduces hitherto unprecedented challenges and dynamics.[2] Others even claim that the term "fake news" should be avoided altogether because it is too vague[3], politically dangerous[4]; indistinguishable from past forms of disinformation[5]; charged with an over-simplistic idea of truth as direct correspondence to reality[6], and missing the most important and dangerous features of the phenomenon it describes which is not deceptiveness, but “spreadability”.[7]

Proposed responses include new media literacy, educational and fact-checking initiatives; new laws, policies and fines for technology companies who fail to remove offending content;[8] and a host of new startups and technical fixes – from authenticated content to automated fact-checking projects.[9]

Across these different kinds of responses, observers agree that the term “fake news” is deceptive and that these problematic fabrications cannot be straightforwardly defined. And while we “follow the actors” [10] and retain the main name by which these activities have been originally turned into an issue of public concern to indicate the controversy that prompted us to undertake this empirical investigation, we recognise that fabrications gathered under the label “fake news” come in many different shades. This need not be taken as proof of the futility of investigating this phenomenon. On the contrary: their different shades are what is at stake in our investigation and accepting that there is no easy way to demarcate between “fake” and “non-fake” across all cases opens interesting research opportunities. It is precisely because its forms and contents are designed to mimic those of mainstream media – and precisely because it travels through similar circuits – that fake news offers us the occasion to study not just the strategies and formats of fakeness, but the politics and composition of the media and information environments of the digital age more generally.

This guide aims to enrich public debate and catalyse collective inquiry around this rapidly evolving and highly contested issue – by suggesting different ways in which it can be empirically studied, mapped and investigated online. Ultimately our hope is not just to provide better accounts of the issue of fake news and phenomena associated with it, but also to contribute to more substantive forms of public engagement around it. We hope this guide will contribute to facilitating broader public debate and involvement around processes of reshaping platforms and policies, laws and infrastructures, technologies and standards that are implicated in the circulation of fake news and other fabrications. This includes remaining attentive to possible unintended consequences of these different responses, as well as other interests and concerns.

The guide explores the notion that fake news is not just another type of content that circulates online, but that it is precisely the *character* of this online circulation and reception that makes something into fake news. In this sense fake news and other fabrications may be considered not just in terms of the form or content of the message, but also in terms of the mediating infrastructures, platforms and participatory cultures which facilitate its circulation. In this sense, the significance of these fabrications *cannot be fully understood apart from their circulation* online. It is the register of this circulation that also enables us to trace how material that starts its life as niche satire can be repackaged as hyper-partisan clickbait to generate advertising money and then continue life as an illustration of dangerous political disinformation.

As a consequence this field guide encourages a shift from focusing on the formal *content* of fabrications in isolation to understanding the contexts in which they *circulate* online. This shift points to the limits of a “deficit model” approach – which might imply that fabrications thrive only because of a deficit of factual information. In the guide we suggest new ways of mapping and responding to fake news beyond identifying and fact-checking suspect claims – including “thicker” accounts of circulation as a way to develop a richer understanding of how fake news moves and mobilises people, more nuanced accounts of “fakeness” and responses which are better attuned to the phenomenon.

While online and platform metrics often serve to take measure of engagement by means of what Theodore Porter calls “thin descriptions”[11] – i.e. aggregated quantities such as total likes, shares, posts – we suggest different ways of exploring how different publics engage with and ascribe meaning to fake news and how this moves and mobilises different actors in the process. In doing so while we start our inquiry with fake news, we end up surfacing a wide range of grassroots political, media and participatory cultures online and the social and political issues around which they assemble. Some of these may challenge and prompt a rethinking of our ideas of the forms and formats of grassroots political action online.

We have adopted the metaphor of the “field guide” in the tradition of a number of recent guides which transpose the language and imagery of mapping places, flora and fauna onto the cloud, digital infrastructures and life online.[12] However this metaphor stands in need of some qualification. Many classical natural historical “field guides” aspire to provide systematic taxonomies of natural phenomena by taking them out of their contexts in order to abstract and compare their features. By contrast with our guide we aim to do precisely the opposite – not to *decontextualise*, but to *recontextualise* fake news phenomena by suggesting ways to follow them “in the wild”: as they travel across the web, search engines, digital platforms, fact-checking initiatives and news websites.

We do not set out to provide a definitive single set of watercolour portraits, anatomical illustrations, cartographic charts, satellite imagery or infrastructural diagrams of the phenomenon in question – or even lists of characteristic features which may be used for the purposes of identification. Instead we illustrate a range of methods and procedures which readers may use in order to explore fake news phenomena online for themselves. As part of this process we wish to extend the repertoire of mapping practices which are publicly available to make sense of fake news online and in this sense the graphics that we provide can be understood as temporary placeholders to encourage further exploration.

We also draw attention to different ways of examining how things are *categorised* and *labelled* as fake news and the politics of these practices of classification. In this sense we hope to cultivate what has been called “critical technical practice”[13] – which in this case would include reflection on the use of digital methods and digital data and how these not only serve to *designate* phenomena which can be straightforwardly and independently picked out, but how these very methods may also be involved in the process of *articulating* what fake news is. As Shannon Mattern puts it, in undertaking to investigate fake news online we should be aware of “the shadows cast by our presence as explorers in the field.”[14] And rather than producing maps for the sake of producing maps, we should consider what maps *do*, who and what they are *for* and the *effects* that they produce as social, cultural and political devices.

Insofar as we focus on providing procedures for inquiry rather than pictures of the phenomena, this guide may also be considered a kind of “recipe book.” Recent research suggests that there is an interesting relation between the documentation of recipes and the emergence of procedural knowledge in the early modern period – such that practices of writing down processes for cooking and craft are entangled with the history of the emergence of scientific method.[15] Over the past few decades the metaphors of the “recipe” and the “cookbook” have also become popular in relation to software programming. In our guide, we illustrate different approaches to mapping and investigating fake news online through a series of methodological “recipes.” As with many cookery books, our aim is not just to support readers in following the specific recipes that we present, but rather to use these recipes to illustrate a certain approach to cooking – with the hope that readers are inspired to adapt, modify and venture beyond them. We also include a number of “serving suggestions” about how they may be put to work.

We hope that the recipes in this guide will enrich investigations of fake news and other fabrications in a way which has affinities with a common narrative approach in mystery fiction – namely the scenario that in pursuit of solving an apparently simple crime, the plot thickens, the cast grows, the questions multiply and there are unexpected twists or changes of perspective. By following the production, circulation and responses to fake news online – we may end up being drawn into things that we do not set out to investigate: whether the media strategies of fake news publishers, propagandists, trolls or bots; the commercial and technical architectures of online content; the politics and dynamics of viral content; and how social life adapts, evolves and innovates in response to some of the world’s biggest online platforms and websites. In this sense, it will be clear that fake news involves more than a few rogue producers or state conspiracies – and raises important and difficult questions about the role of digital technologies in society and how we mutually shape and are shaped by them.

In Edgar Allan Poe’s classic mystery story “The Purloined Letter”[16], the prefect of police – “G” – and his colleagues search for a letter said to contain scandalous information behind wallpaper, under carpets, in the legs of furniture and in cushions, only to eventually find the letter “hiding in plain sight”. In a similar vein, we may consider the algorithmically mediated circulation of fake news on digital platforms in terms of what Noortje Marres characterises as “distributed accomplishment” or what Mike Ananny and Kate Crawford describe as “relational achievement”.[17] This entails a shift from “seeing in” systems as a kind of looking “under the hood”, to “seeing across” a diverse range elements which are implicated in the patterning of collective life online.

Many of the researchers who have contributed to the guide share a background in a field called Science and Technology Studies (STS). Some of the lines of inquiry pursued in the guide are informed by a forthcoming paper exploring what STS can bring to the study of fake news.[18] The recipes are also informed by a “digital methods” research approach that has developed through an engagement with this field and which many of us have contributed to through our teaching and research.[19] We also draw upon our field’s interest in public engagement and participation around digital technologies and data infrastructures.[20] As such our focus is less on advancing particular legal or technical fixes, than on facilitating processes of public engagement and democratic deliberation – including provoking curiosity about different ways of seeing the issue and imagination about the different ways in which we might respond.

The material in this guide has been produced through a series of “data sprints” and research workshops in Amsterdam, Copenhagen and Milan, hosted by members of the Public Data Lab. The “data sprint” is a short form working format that has emerged at the intersection between Science and Technology Studies and New Media Studies, drawing on approaches associated with open-source software development, open data and civic hacking in order to convene a range of actors to collaborate around the co-production of data and research projects – including between fields of practice with different outlooks.[21]

Two of us have a background in data journalism, having co-edited The Data Journalism Handbook and undertaken various initiatives in this field.[22] This guide builds on a long-standing interest in supporting productive encounters between data journalists and digital researchers. While fake news seems like a remarkably ripe area for experimentation between these two fields, just as the writer Jorge Luis Borges lamented being granted “books and night at one touch”[23] it is not without a sense of irony that we note that as public attention around this issue grows, fake news websites are beginning to vanish – leading to proposals for a “fake news archive” amongst our contributing researchers. Happily the approaches and analytical techniques in this guide may be used to inform collaborations between data journalists and digital researchers around the study of other contentious issues and controversies as they unfold on digital media, as well as of the mediating capacities of platforms, algorithms and infrastructures which shape life online.

The data sprint format has also helped us to catalyse new experimentation and empirical work in a comparatively short period of time – a distinct advantage given the pace of developments around fake news. For this we are immensely grateful to researchers, graduates and students at DensityDesign Lab (Politecnico di Milano, Italy), the Digital Methods Initiative (University of Amsterdam, Netherlands), the European Journalism Centre, the Laboratoire Interdisciplinaire Sciences Innovations Sociétés (Université Paris-Est, France), the médialab (Sciences Po, Paris, France), the Media of Cooperation research group (University of Siegen, Germany), the STS-Lab (University of Lausanne, Switzerland) and the Techno-Anthropology Lab (Aalborg University Copenhagen, Denmark) – without whose energy, creativity and dedication this project would not have been possible.

*Jonathan Gray (@jwyg), Liliana Bounegru (@bb_liliana), Tommaso Venturini (@TommasoVenturin)*
*London, March 2017*

> [1] See, for example, Robert Darnton, “The True History of Fake News”, The New York Review of Books, February 2017, available at: http://www.nybooks.com/daily/2017/02/13/the-true-history-of-fake-news/

> [2] See, for example, “Sky Views: Facebook's fake news threatens democracy”, Sky News: http://news.sky.com/story/sky-views-democracy-burns-as-facebook-lets-fake-news-thrive-10652711

> [3] See Edson Tandoc, Zheng Wei Lim & Richard Ling "Defining ‘Fake News’", Digital Journalism, 811, August 2017. pp. 1–17. 2017. Available at: https://www.tandfonline.com/doi/full/10.1080/21670811.2017.1360143 

> [4] See Claire Wardle & Derakhshan Hossein, Information Disorder: Toward an interdisciplinary framework for research and policymaking (Report to the Council of Europe), 2017.

> [5] See Caroline Jack, What’s Propaganda Got To Do With It? Available at: https://points.datasociety.net/whats-propaganda-got-to-do-with-it-5b88d78c3282

> [6]. See Michael Lynch, Post-truth, alt-facts, and asymmetric controversies, 2017, First 100 Days, Available at: http://first100days.stsprogram.org/2017/02/06/post-truth-alt-facts-and-asymmetric-controversies-part-i/ 

> [7] See Henry Jenkins, Sam Ford, & Joshua Benjamin Green, Spreadable media. New York: New York University Press, 2017, Available at: http://doi.org/10.1017/CBO9781107415324.004 

> [8] See, John Naughton, “Facebook and Twitter could pay the price for hate speech”, The Guardian, March 2017: https://www.theguardian.com/commentisfree/2017/mar/19/john-naughton-germany-fine-social-media-sites-facebook-twitter-hate-speech

> [9] See, for example, Full Fact, “The State of Automated Factchecking”, https://fullfact.org/automated and Lori Hawkins, “Austin startup wants to end fake news - and fake everything else - on the internet”, 512Tech, February 2017:  http://www.512tech.com/technology/austin-startup-wants-end-fake-news-and-fake-everything-else-the-internet/EcchWFgrl4PQmjPvmkzycJ/

> [10] Bruno Latour, Reassembling the Social: An Introduction to Actor-Network-Theory, Oxford: Oxford University Press, 2009

> [11] See Theodore Porter, “Thin Description: Surface and Depth in Science and Science Studies.” Osiris, 2012: www.jstor.org/stable/10.1086/667828. 

> [12] For a recent overview see Shannon Mattern’s “Cloud and Field”, Places Journal, August 2016: https://placesjournal.org/article/cloud-and-field/

> [13] See Philip E. Agre, “Toward a Critical Technical Practice: Lessons Learned in Trying to Reform AI”, in Geof Bowker, Les Gasser, Leigh Star and Bill Turner (eds), “Bridging the Great Divide: Social Science, Technical Systems and Cooperative Work", NJ: Erlbaum, 1997. Available at: http://polaris.gseis.ucla.edu/pagre/critical.html

> [14] Shannon Mattern, “Cloud and Field”, Places Journal, August 2016: https://placesjournal.org/article/cloud-and-field/

> [15] See, for example, the work of Pamela Smith and her colleagues on the “Making and Knowing” project at Columbia University: http://recipes.hypotheses.org/7430, February 2016, and http://www.makingandknowing.org/.

> [16] Edgar Allan Poe and Jacob Schwartz, “The Purloined Letter”, London: Ulysses bookshop, 1931.

> [17] See, Noortje Marres, “The Redistribution of Methods: On Intervention in Digital Social Research, Broadly Conceived”, The Sociological Review, June 2012; and Mike Ananny and Kate Crawford, “Seeing Without Knowing: Limitations of the Transparency Ideal and its Application to Algorithmic Accountability”, New Media and Society, December 2016.

> [18] Liliana Bounegru, Mette Simonsen Abildgaard, Andreas Birkbak, Jonathan Gray, Mathieu Jacomy, Torben Elgaard Jensen, Anders Koed Madsen and Anders Kristian Munk, "Five Provocations about Fake News" (under review).

> [19] See, for example, Richard Rogers, “Digital Methods”, 2013, Cambridge, MA: MIT Press.

> [20] See, for example, Noortje Marres, “Material Participation: Technology, the Environment and Everyday Publics”, London: Palgrave Macmillan, 2012.

> [21] See Tommaso Venturini, Anders Munk and Axel Meunier, “Data-Sprint: A Public Approach to Digital Research” in C. Lury, P. Clough, M. Michael, R. Fensham, S. Lammes, A. Last, & E. Uprichard (Eds.) “Interdisciplinary Research Methods”, London: Routledge, 2017.

> [22] Jonathan Gray, Liliana Bounegru and Lucy Chambers (Eds.) “The Data Journalism Handbook”, Sebastopol, CA: O’Reilly Media, 2012, available at: http://datajournalismhandbook.org/

> [23] Upon being invited to become Director of the Argentine National Library at a moment which coincided with the deterioration of his eyesight, Borges famously wrote: “No one should read self-pity or reproach / into this statement of the majesty / of God; who with such splendid irony / Granted me books and night at one touch”. See J. L. Borges, “Poem of the Gifts” in “Selected Poems: Volume 2”, London: Penguin Books, 2000, p. 95.
